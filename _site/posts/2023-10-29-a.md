
{% include header.md %}

# The `ffmpeg` manifesto

## Creating a blurred overlay

### 2023 Oct 29

We believe video editing software should be free and open.

We believe GUIs are bloatware which do not lend themselves to reusable
scriptable workflows.

We believe CLIs are the ideal type of interface.

Just kidding, I'm not going to write a whole blog post in this style.

## The gargantuan one-liner

Let's say you want to take a widescreen video in `16:9` aspect ratio and post it
somewhere like [TikTok](www.tiktok.com) or Reels.  The only problem is that
those are mobile-friendly vertical video platforms, so a widescreen video isn't
ideal.  Instead of a short fat widescreen video, you need a tall skinny vertical
video.

One common hack is to overlay the original widescreen video centered overtop of
a blurred and cropped background in the correct vertical aspect ratio, `9:16`
instead of `16:9`.

You can do this with a single gargantuan one-liner [`ffmpeg`](ffmpeg.org) command:

{% highlight shell %}
ffmpeg \
	-i "input.mp4" \
	-vf "split [fg][bg];
	[bg]        crop=ceil(ih*9/16/2)*2:ih, boxblur=30 [bg];
	[fg]       scale=ceil(ih*9/16/2)*2:ceil(ih*9*9/16/16/2)*2 [fg];
	[bg][fg] overlay=y=main_h/2-overlay_h/2" \
	"output.mp4"
{% endhighlight %}

We'll break this down step by step below.

## Getting help with `ffmpeg`

<!-- TODO: move part of next section above this? -->

To get top-level help, use `ffmpeg --help` or `ffmpeg -h`:

{% highlight shell %}
ffmpeg -h

# Hyper fast Audio and Video encoder
# usage: ffmpeg [options] [[infile options] -i infile]... {[outfile options] outfile}...
# 
# Getting help:
#     -h      -- print basic options
#     -h long -- print more options
# 
# Video options:
# -vframes number     set the number of video frames to output
# -r rate             set frame rate (Hz value, fraction or abbreviation)
# -s size             set frame size (WxH or abbreviation)
# -vf filter_graph    set video filters
{% endhighlight %}

There's a long verbose banner with version and build info before the actual help
starts, and a lot of other "basic" options which I've omitted.  For someone used
to keyword arguments which don't depend on position, it can be confusing that
there are separate `[infile options]` and `[outfile options]` which *do* depend
on where they are positioned in the argument list.

To get help with filters, use `ffmpeg -filters`:

{% highlight shell %}
ffmpeg -filters

# Filters:
#   T.. = Timeline support
#   .S. = Slice threading
#   ..C = Command support
#   A = Audio input/output
#   V = Video input/output
#   N = Dynamic number and/or type of input/output
#   | = Source or sink filter
#  T.. boxblur           V->V       Blur the input.
#  ..C crop              V->V       Crop the input video.
#  TSC overlay           VV->V      Overlay a video source on top of the input.
#  ..C scale             V->V       Scale the input video size and/or convert the image format.
{% endhighlight %}

It feels inconsistent, but notice there's no `-h` in the above filters help command.
Again, I've omitted everything that's irrelevant to this blog.

Finally, to get help with a specific filter, e.g. `crop`, use `ffmpeg -h filter=crop`:

{% highlight shell %}
ffmpeg -h filter=crop

# Filter crop
#   Crop the input video.
#     Inputs:
#        #0: default (video)
#     Outputs:
#        #0: default (video)
# crop AVOptions:
#   out_w             <string>     ..FV..... set the width crop area expression (default "iw")
#   w                 <string>     ..FV..... set the width crop area expression (default "iw")
#   out_h             <string>     ..FV..... set the height crop area expression (default "ih")
#   h                 <string>     ..FV..... set the height crop area expression (default "ih")
#   x                 <string>     ..FV..... set the x crop area expression (default "(in_w-out_w)/2")
#   y                 <string>     ..FV..... set the y crop area expression (default "(in_h-out_h)/2")
#   keep_aspect       <boolean>    ..FV..... keep aspect ratio (default false)
#   exact             <boolean>    ..FV..... do exact cropping (default false)
{% endhighlight %}

The [online ffmpeg help](https://ffmpeg.org/ffmpeg-filters.html) can be better
at providing examples for filters like this.  Putting all the help together,
here's an example crop command:

{% highlight shell %}
ffmpeg -i "input.mp4" -filter "crop=608:1080" "crop.mp4"
{% endhighlight %}

## Breaking down the one-liner

`ffmpeg` is intimidating.  You get lured in with straightforward conversion
commands, e.g. converting `avi` to `mp4`, like this with just a couple
command-line arguments:

{% highlight shell %}
ffmpeg -i "input.avi" "output.mp4"
{% endhighlight %}

<!-- the thing about lossyness is wrong -->
<!-- Not to mention `ffmpeg` uses killer codecs that can often compress video files
produced by other tools down to 10 times smaller files without any lossyness or
downgraded resolution. -->

And then there are moderately more advanced commands to apply video filters,
e.g. scaling an input resolution down or up to HD resolution `1920:1080`:

{% highlight shell %}
ffmpeg -i "input.mp4" -filter:video "scale=1920:1080" "output.mp4"
{% endhighlight %}

<!-- TODO: stack links -->
And finally there are gargantuan one-liners, like the one above, which you might
find on stackoverflow posts from `ffmpeg` wizards.

<!--
TODO: repeat?
{% highlight shell %}
ffmpeg \
	-i "input.mp4" \
	-vf "split [fg][bg];
	[bg]        crop=ceil(ih*9/16/2)*2:ih, boxblur=30 [bg];
	[fg]       scale=ceil(ih*9/16/2)*2:ceil(ih*9*9/16/16/2)*2 [fg];
	[bg][fg] overlay=y=main_h/2-overlay_h/2" \
	"output.mp4"
{% endhighlight %}
-->

How does anyone come up with these?  What seemed like a problem of crafting a
few command line arguments has evolved into a task of writing a weird
interpretted programming language complete with variables like `[fg]` and
`[bg]`, mathematical operations and the `ceil()` function, and bizarrely
abbreviated constant variables like `ih` and `main_h`.

I'll be honest, it took me a couple hours of trial and error to settle on this
one-liner.  I started step by step with a workflow that used 4 separate
commands:

1. Crop the background to a vertical aspect ratio
2. Blur the background
3. Scale the foreground down to match the background's width
4. Overlay the foreground onto the background

### Fixed `1920:1080` resolution

Here are those steps translated into `ffmpeg` commands, assuming the input has
dimensions `1920:1080`:

<!-- first, fixed resolution 1920:1080 -->

<!-- TODO: re-test -->
{% highlight shell %}
ffmpeg -i "input.mp4" -vf "crop=608:1080" "crop.mp4"
ffmpeg -i "crop.mp4" -vf "boxblur=30" "blur.mp4"
ffmpeg -i "input.mp4" -vf "scale=608:342" "scale.mp4"
ffmpeg -i "blur.mp4" -i "scale.mp4" -vf "overlay=y=369" "output.mp4"
{% endhighlight %}

The short option `-vf` is an alias of the long options `-filter`, `-filter:v`,
or `-filter:video`.  Why specify `video`?  Because `ffmpeg` can filter audio
too!

Every video filter has arguments.  For example, the `crop` filter takes `width`
and `height` arguments with the syntax `crop=width:height`, e.g.
`crop=608:1080`.  This filter takes the `1920:1080` input (`16:9` aspect) and
crops to the middle `608:1080` (`9:16` aspect).  The `crop` filter has other
optional arguments listed in the help above that can crop other areas besides
the middle.  We'll figure out how to generalize this to other input dimensions
with the same aspect ratio below.

The `boxblur` filter has an argument to control the blurriness.

The `scale` filter downsizes the input to `608:342`, the same width as the
crop (`608`) with the original `16:9` aspect ratio.

Finally, the `overlay` filter lays the scaled video over the middle of the
blurred video, at a `y` position `369`.  We have to do a little math to figure
out the middle position.  Here it is half the blur height minus half the overlay
height, i.e. `0.5 * 1080 - 0.5 * 342 = 369`.

### General `16:9` aspect ratio

Instead of hard-coding dimensions for a `1920:1080` input, these can be
generalized to work with any `16:9` aspect ratio, e.g. `1280:720`, HD
`1920:1080`, 4k `3840:2160`, etc.

This can be achieved by using named variables accepted by many filters in
`ffmpeg`, e.g. `ih` for the height of the input frame:

<!-- then, substitute vars for general resolution -->

{% highlight shell %}
<!-- ffmpeg -i "${input}.mp4" -vf "crop=ceil(ih*9/16/2)*2:ih, boxblur=30" "${input}-blur.mp4" -->
ffmpeg -i "input.mp4" -vf "crop=ceil(ih*9/16/2)*2:ih" "crop.mp4"

ffmpeg -i "crop.mp4" -vf "boxblur=30" "blur.mp4"

ffmpeg -i "input.mp4" \
	-vf "scale=ceil(ih*9/16/2)*2:ceil(ih*9*9/16/16/2)*2" \
	"scale.mp4"

ffmpeg -i "blur.mp4" -i "scale.mp4" \
	-vf "overlay=y=main_h/2-overlay_h/2" "output.mp4"
{% endhighlight %}

Many filters accept `ih` for the input height and `iw` for the input width.  The
`overlay` filter is slightly more complicated because there are two inputs and
thus two heights: `main_h` and `overlay_h`.  If you get the main and overlay
inputs mixed up like I do, just remember that the *overlay* input gets layed *over*
the main input.

I should explain the funny `ceil()` function in the `crop` and `scale` filters,
e.g. `crop=ceil(ih*9/16/2)*2:ih`.  Ideally we would want a cropped width of just
`ih*9/16`, but some formats and codecs will error out if you try to use an odd
numbered dimension.  To guarantee an even number, we can divide by 2, round up,
and multiply by 2 again, hence `ceil(ih*9/16/2)*2`.  The `scale` filter is
similar.

Further generalization to other aspect ratio inputs and outputs like `4:3` is
left as an exercise for the reader.

## Chaining steps together into a filtegraph

The workflow above leaves a few temporary files `crop.mp4`, `blur.mp4`, and
`scale.mp4` which can be cleaned up.  The gargantuan one-liner is better because
it does not waste any time reading and writing temporary files.

Again, take things one step at a time when chaining together these gargantuan
one-liners.  To start, the first to steps of cropping an blurring can be
combined:

{% highlight shell %}
ffmpeg -i "input.mp4" -vf "crop=ceil(ih*9/16/2)*2:ih" "crop.mp4"
ffmpeg -i "crop.mp4" -vf "boxblur=30" "blur.mp4"
{% endhighlight %}

The same filters in a single step look like this:

{% highlight shell %}
ffmpeg -i "${input}.mp4" -vf "crop=ceil(ih*9/16/2)*2:ih, boxblur=30" "${input}-blur.mp4"
{% endhighlight %}

The video filters `-vf` are quoted in a single string separated by commas, e.g.
`"crop=filter1, filter2"`, which becomes `"crop=ceil(ih*9/16/2)*2:ih, boxblur=30" `.

The [`ffmpeg` filtering
introduction](https://ffmpeg.org/ffmpeg-filters.html#Filtering-Introduction)
explains this excellently:

> Filters in the same linear chain are separated by commas, and distinct linear chains of filters are separated by semicolons. 

Again, the `overlay` filter is more complicated, because it takes two inputs.
To apply this filter without any intermediate files, we have to `split` the
input stream into two streams:  (1) the cropped and blurred background `[bg]`
and (2) the scaled foreground `[fg]`.  The labels `[bg]` and `[fg]` are dummy
variables.  We can name them anything we want using the `[bracket]` syntax.

{% highlight shell %}
ffmpeg \
	-i "input.mp4" \
	-vf "split [fg][bg];
	[bg]        crop=ceil(ih*9/16/2)*2:ih, boxblur=30 [bg];
	[fg]       scale=ceil(ih*9/16/2)*2:ceil(ih*9*9/16/16/2)*2 [fg];
	[bg][fg] overlay=y=main_h/2-overlay_h/2" \
	"output.mp4"
{% endhighlight %}

In two distinct linear chains, the background `[bg]` is cropped and blurred,
while the foreground `[fg]` is scaled.  Finally, foreground is layed over the
background.

<!-- TODO: screenshots and links to example final products -->


